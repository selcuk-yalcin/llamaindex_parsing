# HÄ±zlÄ± BaÅŸlangÄ±Ã§ KÄ±lavuzu

## ğŸš€ 5 Dakikada BaÅŸla

### 1. Kurulum

```bash
# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# .env dosyasÄ±nÄ± oluÅŸtur
cp .env.example .env

# API key'lerini dÃ¼zenle
nano .env
```

### 2. API Key'leri Ayarla

`.env` dosyasÄ±nÄ± dÃ¼zenleyin:

```bash
LLAMA_CLOUD_API_KEY=llx-your-key-here
OPENAI_API_KEY=sk-your-key-here
```

**API Key NasÄ±l AlÄ±nÄ±r:**
- **LlamaCloud**: https://cloud.llamaindex.ai â†’ Sign up â†’ API Keys
- **OpenAI**: https://platform.openai.com â†’ API Keys â†’ Create new key

### 3. Ä°lk Testinizi YapÄ±n

```bash
# Pydantic modellerini test et
python test_models.py
```

âœ… Ã‡Ä±ktÄ±: `test_output.json` dosyasÄ± oluÅŸturulmalÄ±

### 4. PDF Ä°ÅŸleme

#### YÃ¶ntem 1: Python Script

```python
from batch_extractor import LegalDocumentExtractor
import os

extractor = LegalDocumentExtractor(
    llama_parse_api_key=os.getenv("LLAMA_CLOUD_API_KEY"),
    llm_provider="openai",
    llm_api_key=os.getenv("OPENAI_API_KEY"),
    llm_model="gpt-4o"
)

# Tek dosya iÅŸle
result = extractor.process_single_document("./kanun.pdf")
print(f"SonuÃ§: {result['json_path']}")
```

#### YÃ¶ntem 2: CLI

```bash
# Tek dosya
python cli_extractor.py --file kanun.pdf

# KlasÃ¶r
python cli_extractor.py --directory ./data/laws
```

## ğŸ“ Proje YapÄ±sÄ±

```
llamaindex-parsing/
â”‚
â”œâ”€â”€ pydantic_models.py          # Veri modelleri (JSON ÅŸema)
â”œâ”€â”€ batch_extractor.py          # Ana iÅŸlem motoru
â”œâ”€â”€ cli_extractor.py            # Komut satÄ±rÄ± arayÃ¼zÃ¼
â”œâ”€â”€ mongodb_integration.py      # MongoDB entegrasyonu
â”œâ”€â”€ examples.py                 # KullanÄ±m Ã¶rnekleri
â”œâ”€â”€ test_models.py              # Test scripti
â”‚
â”œâ”€â”€ requirements.txt            # BaÄŸÄ±mlÄ±lÄ±klar
â”œâ”€â”€ .env.example               # Ã–rnek Ã§evre deÄŸiÅŸkenleri
â”œâ”€â”€ README.md                  # DetaylÄ± dokÃ¼mantasyon
â”œâ”€â”€ QUICKSTART.md              # Bu dosya
â”‚
â”œâ”€â”€ data/                      # PDF dosyalarÄ± (sizin eklemeniz gerekli)
â”‚   â””â”€â”€ laws/
â”‚       â”œâ”€â”€ 6331_sayili_kanun.pdf
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ extracted_laws/            # Ã‡Ä±ktÄ±: JSON dosyalarÄ±
â”‚   â”œâ”€â”€ 6331_sayili_kanun.json
â”‚   â””â”€â”€ batch_summary_*.json
â”‚
â”œâ”€â”€ parsed_markdown/           # Ã‡Ä±ktÄ±: Markdown dosyalarÄ±
â”‚   â””â”€â”€ 6331_sayili_kanun.md
â”‚
â””â”€â”€ extraction.log             # Log dosyasÄ±
```

## ğŸ¯ KullanÄ±m SenaryolarÄ±

### Senaryo 1: Tek Kanun Ä°ÅŸle

```bash
python cli_extractor.py --file ./data/6331_sayili_kanun.pdf
```

**Ã‡Ä±ktÄ±:**
- `extracted_laws/6331_sayili_kanun.json` âœ…
- `parsed_markdown/6331_sayili_kanun.md` âœ…

### Senaryo 2: Toplu Ä°ÅŸlem (Batch)

```bash
python cli_extractor.py --batch \
  ./data/6331_sayili_kanun.pdf \
  ./data/4857_sayili_kanun.pdf \
  ./data/5510_sayili_kanun.pdf
```

### Senaryo 3: KlasÃ¶r Ä°ÅŸle

```bash
python cli_extractor.py --directory ./data/laws
```

### Senaryo 4: MongoDB'ye Kaydet

```python
from mongodb_integration import LegalDocumentDatabase

db = LegalDocumentDatabase()
db.bulk_insert_from_json_files("./extracted_laws")

# Arama yap
results = db.search_articles("iÅŸ gÃ¼venliÄŸi", limit=10)
```

## ğŸ’¡ Ä°puÃ§larÄ±

### Maliyet Optimizasyonu

1. **Gemini Kullan** (daha ucuz):
```bash
python cli_extractor.py --file kanun.pdf --llm gemini --model gemini-1.5-pro
```

2. **Chunk Size Ayarla** (uzun dÃ¶kÃ¼manlar iÃ§in):
```bash
python cli_extractor.py --file kanun.pdf --chunk-size 30000
```

### Hata Ã‡Ã¶zÃ¼mleri

**Hata: `API rate limit exceeded`**
```
Ã‡Ã¶zÃ¼m: LlamaParse Ã¼cretsiz kotanÄ±z dolmuÅŸ. Pro plana geÃ§in veya yarÄ±n tekrar deneyin.
```

**Hata: `ValidationError: field required`**
```
Ã‡Ã¶zÃ¼m: LLM bazÄ± alanlarÄ± Ã§Ä±karamadÄ±. Daha gÃ¼Ã§lÃ¼ model kullanÄ±n (gpt-4o).
```

**Hata: `Import "llama_parse" could not be resolved`**
```
Ã‡Ã¶zÃ¼m: pip install llama-parse
```

## ğŸ“Š Performans Beklentileri

| DÃ¶kÃ¼man Boyutu | Parse SÃ¼resi | Extraction SÃ¼resi | Maliyet (GPT-4o) |
|----------------|--------------|-------------------|------------------|
| 10 sayfa       | ~20 saniye   | ~15 saniye        | ~$0.10          |
| 50 sayfa       | ~40 saniye   | ~30 saniye        | ~$0.40          |
| 100 sayfa      | ~60 saniye   | ~50 saniye        | ~$0.80          |

## ğŸ”§ GeliÅŸmiÅŸ KullanÄ±m

### Ã–zel Prompt KullanÄ±mÄ±

`batch_extractor.py` iÃ§indeki `_get_extraction_prompt()` metodunu dÃ¼zenleyin:

```python
def _get_extraction_prompt(self) -> str:
    return """
    [Ã–zel prompt'unuzu buraya yazÄ±n]
    
    {text}
    """
```

### Retry MekanizmasÄ±

```python
from tenacity import retry, wait_exponential, stop_after_attempt

@retry(wait=wait_exponential(min=1, max=10), stop=stop_after_attempt(3))
def process_with_retry(file_path):
    return extractor.process_single_document(file_path)
```

## ğŸ“ Destek

**Sorun mu yaÅŸÄ±yorsunuz?**

1. `extraction.log` dosyasÄ±nÄ± kontrol edin
2. `python test_models.py` Ã§alÄ±ÅŸtÄ±rÄ±n
3. API key'lerinizi doÄŸrulayÄ±n
4. BaÄŸÄ±mlÄ±lÄ±klarÄ± yeniden yÃ¼kleyin: `pip install -r requirements.txt --upgrade`

## ğŸ“ Sonraki AdÄ±mlar

1. âœ… Ä°lk dÃ¶kÃ¼manÄ±nÄ±zÄ± iÅŸleyin
2. âœ… MongoDB entegrasyonunu kurun
3. âœ… Toplu iÅŸlem yapÄ±n
4. âœ… RAG sisteminize entegre edin

**BaÅŸarÄ±lar!** ğŸš€

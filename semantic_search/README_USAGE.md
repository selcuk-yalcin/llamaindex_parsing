# ISG Mevzuat Semantic Search - KullanÄ±m KÄ±lavuzu

## Kurulum

### 1. Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:
```bash
pip install python-dotenv datasets PyPDF2 openai google-generativeai sentence-transformers pinecone-client torch tqdm
```

### 2. .env dosyasÄ±nÄ± kontrol edin
`.env` dosyasÄ±nda ÅŸunlar olmalÄ±:
```
PINECONE_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here
GOOGLE_API_KEY=your_key_here
```

## Ã‡alÄ±ÅŸtÄ±rma

### Tek komutla Ã§alÄ±ÅŸtÄ±rma:
```bash
python semantic_search_isg.py
```

Bu komut:
1. PDF'i yÃ¼kler ve iÅŸler
2. Pinecone index oluÅŸturur
3. Embeddings yÃ¼kler
4. 3 Ã¶rnek sorgu Ã§alÄ±ÅŸtÄ±rÄ±r
5. Interactive mode'a geÃ§er

### Python'dan kullanma:
```python
from semantic_search_isg import run_query, main

# Setup yap
index, model, text_mapping = main()

# Sorgular Ã§alÄ±ÅŸtÄ±r
run_query('iÅŸ kazasÄ± nedir?', index, model, text_mapping, 
          use_ai=True, ai_provider='gemini')

run_query('iÅŸveren yÃ¼kÃ¼mlÃ¼lÃ¼kleri', index, model, text_mapping,
          ai_provider='openai', max_length='short')

run_query('gÃ¼venlik eÄŸitimi', index, model, text_mapping, 
          use_ai=False)
```

## Parametreler

### run_query() parametreleri:
- `query`: Soru (TÃ¼rkÃ§e)
- `use_ai`: AI kullan (True/False)
- `ai_provider`: "openai", "gemini", veya "none"
- `use_reasoning`: Reasoning modeli kullan (True/False)
- `max_length`: "short" (3-4 cÃ¼mle), "medium" (5-7 cÃ¼mle), "normal" (detaylÄ±)
- `top_k`: KaÃ§ chunk getir (default: 5)

## AI Provider SeÃ§enekleri

### 1. Google Gemini (ÃœCRETSÄ°Z! ğŸ‰)
```python
# Normal - Gemini 1.5 Flash (en hÄ±zlÄ±!)
run_query(query, index, model, text_mapping, ai_provider='gemini')

# Reasoning ile - Gemini 1.5 Pro (deep thinking)
run_query(query, index, model, text_mapping, 
          ai_provider='gemini', use_reasoning=True)
```

### 2. OpenAI GPT-4 (Ãœcretli)
```python
# Normal
run_query(query, index, model, text_mapping, ai_provider='openai')

# O1 Reasoning ile
run_query(query, index, model, text_mapping,
          ai_provider='openai', use_reasoning=True)
```

### 3. AI Yok (Sadece semantic search)
```python
run_query(query, index, model, text_mapping, use_ai=False)
```

## Maliyet KarÅŸÄ±laÅŸtÄ±rmasÄ±

- **Gemini 1.5 Flash**: ÃœCRETSÄ°Z (1,500 istek/gÃ¼n) - EN HIZLI (5-10 saniye)
- **Gemini 1.5 Pro**: ÃœCRETSÄ°Z (reasoning iÃ§in) - HIZLI (8-15 saniye)
- **GPT-4 Turbo**: $10/1M input token - YAVAÅ (15-25 saniye)
- **O1-Preview**: $15/1M input token - Ã‡OK YAVAÅ (20-30 saniye)

**Ã–nerilen:** HÄ±z ve maliyet iÃ§in Gemini 1.5 Flash kullanÄ±n!

## Ã–rnekler

### KÄ±sa cevap (Gemini):
```python
run_query('iÅŸveren sorumluluklarÄ± nelerdir?', 
          index, model, text_mapping,
          ai_provider='gemini', max_length='short')
```

### DetaylÄ± analiz (Gemini Reasoning):
```python
run_query('iÅŸveren ve Ã§alÄ±ÅŸanlarÄ±n iÅŸ kazalarÄ±nÄ± Ã¶nlemedeki sorumluluklarÄ± nelerdir?',
          index, model, text_mapping,
          ai_provider='gemini', use_reasoning=True)
```

### Sadece ilgili metinler (AI yok):
```python
run_query('iÅŸ kazasÄ± durumunda ne yapÄ±lmalÄ±dÄ±r?',
          index, model, text_mapping,
          use_ai=False)
```
